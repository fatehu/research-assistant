"""
Notebook ä¸“ç”¨å·¥å…·é›† - è®© Agent èƒ½å¤Ÿç›´æ¥æ“ä½œ Notebook

å·¥å…·åˆ—è¡¨:
1. NotebookExecuteTool - åœ¨ Notebook å†…æ ¸ä¸­æ‰§è¡Œä»£ç 
2. NotebookVariablesTool - è·å–å½“å‰å˜é‡çŠ¶æ€
3. NotebookCellTool - æ“ä½œå•å…ƒæ ¼ (æ·»åŠ /åˆ é™¤/æ›´æ–°)
4. PipInstallTool - å®‰è£… Python åŒ…
5. WebScrapeTool - çˆ¬å–ç½‘é¡µå†…å®¹
6. CodeAnalysisTool - ä»£ç åˆ†æå’Œä¼˜åŒ–å»ºè®®
"""
import json
import re
import sys
import asyncio
import subprocess
from typing import Dict, Any, Optional, List
from dataclasses import dataclass
from datetime import datetime
from loguru import logger
import httpx
from urllib.parse import urlparse

# å°è¯•å¯¼å…¥ bs4ï¼Œå¦‚æœå¤±è´¥åˆ™åœ¨ä½¿ç”¨æ—¶æŠ¥é”™
try:
    from bs4 import BeautifulSoup
    BS4_AVAILABLE = True
except ImportError:
    BS4_AVAILABLE = False

from app.services.agent_tools import Tool, ToolResult


# ========== å®‰å…¨é…ç½® ==========

# pip install ç™½åå• - åªå…è®¸å®‰è£…è¿™äº›åŒ…
ALLOWED_PACKAGES = {
    # æ•°æ®ç§‘å­¦åŸºç¡€
    'numpy', 'pandas', 'scipy', 'statsmodels',
    # å¯è§†åŒ–
    'matplotlib', 'seaborn', 'plotly', 'bokeh', 'altair', 'pygal',
    # æœºå™¨å­¦ä¹ 
    'scikit-learn', 'sklearn', 'xgboost', 'lightgbm', 'catboost',
    # æ·±åº¦å­¦ä¹ 
    'torch', 'torchvision', 'torchaudio', 'tensorflow', 'keras',
    'transformers', 'datasets', 'accelerate',
    # NLP
    'nltk', 'spacy', 'gensim', 'jieba', 'snownlp',
    # å›¾åƒå¤„ç†
    'pillow', 'opencv-python', 'opencv-python-headless', 'imageio',
    # ç½‘ç»œè¯·æ±‚
    'requests', 'httpx', 'aiohttp', 'urllib3',
    # æ•°æ®è§£æ
    'beautifulsoup4', 'bs4', 'lxml', 'html5lib', 'cssselect',
    'pyquery', 'parsel',
    # æ•°æ®æ ¼å¼
    'openpyxl', 'xlrd', 'xlwt', 'python-docx', 'PyPDF2', 'pdfplumber',
    'python-pptx', 'csvkit',
    # æ•°æ®åº“
    'sqlalchemy', 'pymysql', 'psycopg2-binary', 'redis', 'pymongo',
    # å·¥å…·åº“
    'tqdm', 'loguru', 'rich', 'typer', 'click',
    'pydantic', 'python-dotenv', 'python-dateutil', 'pytz',
    # ç§‘å­¦è®¡ç®—
    'sympy', 'networkx', 'igraph',
    # å…¶ä»–å¸¸ç”¨
    'faker', 'arrow', 'pendulum', 'humanize',
    'tabulate', 'prettytable', 'colorama',
}

# ç½‘é¡µçˆ¬å–é»‘åå•åŸŸå
BLOCKED_DOMAINS = {
    'localhost', '127.0.0.1', '0.0.0.0',
    'internal', 'intranet', 'corp', 'private',
}


# ========== å·¥å…·å®ç° ==========

class NotebookExecuteTool(Tool):
    """
    åœ¨ Notebook å†…æ ¸ä¸­æ‰§è¡Œ Python ä»£ç 
    
    è¿™æ˜¯æœ€æ ¸å¿ƒçš„å·¥å…·ï¼Œè®© Agent èƒ½å¤Ÿç›´æ¥æ“æ§ Notebook ç¯å¢ƒ
    æ‰§è¡Œåä¼šè‡ªåŠ¨åœ¨ Notebook ä¸­åˆ›å»ºæ–°çš„ Cell å¹¶ä¿å­˜ç»“æœ
    """
    name = "notebook_execute"
    description = """åœ¨ Notebook çš„ Python å†…æ ¸ä¸­æ‰§è¡Œä»£ç ã€‚
ä»£ç ä¼šåœ¨æŒä¹…åŒ–çš„å‘½åç©ºé—´ä¸­æ‰§è¡Œï¼Œå˜é‡åœ¨å¤šæ¬¡è°ƒç”¨ä¹‹é—´ä¿æŒã€‚
æ‰§è¡Œåä¼šè‡ªåŠ¨åœ¨ Notebook ä¸­åˆ›å»ºæ–°çš„ä»£ç å•å…ƒæ ¼å¹¶æ˜¾ç¤ºç»“æœã€‚
é€‚ç”¨äºï¼šè¿è¡Œæ•°æ®åˆ†æä»£ç ã€åˆ›å»ºå›¾è¡¨ã€æµ‹è¯•ä»£ç ç‰‡æ®µç­‰ã€‚
æ³¨æ„ï¼šæ­¤æ“ä½œéœ€è¦ç”¨æˆ·æˆæƒã€‚"""
    parameters = {
        "type": "object",
        "properties": {
            "code": {
                "type": "string",
                "description": "è¦æ‰§è¡Œçš„ Python ä»£ç "
            },
            "description": {
                "type": "string",
                "description": "ä»£ç åŠŸèƒ½æè¿°ï¼ˆå¯é€‰ï¼Œç”¨äºæ—¥å¿—ï¼‰"
            }
        },
        "required": ["code"]
    }
    
    def __init__(self, kernel_manager, notebook_id: str, notebooks_store: dict = None, user_authorized: bool = False):
        self.kernel_manager = kernel_manager
        self.notebook_id = notebook_id
        self.notebooks_store = notebooks_store
        self.user_authorized = user_authorized
    
    async def execute(self, code: str, description: str = None, **kwargs) -> ToolResult:
        """æ‰§è¡Œä»£ç å¹¶åˆ›å»º Cell"""
        import uuid
        from datetime import datetime
        
        logger.info(f"[NotebookExecute] notebook_id={self.notebook_id}, authorized={self.user_authorized}")
        logger.debug(f"[NotebookExecute] ä»£ç : {code[:200]}...")
        
        # æ£€æŸ¥æˆæƒ
        if not self.user_authorized:
            return ToolResult(
                success=False,
                output="æ‰§è¡Œä»£ç éœ€è¦ç”¨æˆ·æˆæƒã€‚è¯·å…ˆå¯ç”¨ã€Œå…è®¸ AI æ“ä½œ Notebookã€é€‰é¡¹ã€‚",
                error="authorization_required",
                data={"requires_authorization": True, "action": "execute_code"}
            )
        
        try:
            # è·å–å†…æ ¸
            kernel = self.kernel_manager.get_or_create_kernel(self.notebook_id)
            
            # æ‰§è¡Œä»£ç 
            result = kernel.execute(code, timeout=60)
            
            # å°† outputs è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
            serialized_outputs = []
            for output in result.get('outputs', []):
                if hasattr(output, 'model_dump'):
                    serialized_outputs.append(output.model_dump())
                elif hasattr(output, 'dict'):
                    serialized_outputs.append(output.dict())
                else:
                    serialized_outputs.append(output)
            
            # åˆ›å»ºæ–°çš„ Cell å¹¶æ·»åŠ åˆ° Notebook
            new_cell_id = None
            new_cell = None
            if self.notebooks_store is not None and self.notebook_id in self.notebooks_store:
                notebook = self.notebooks_store[self.notebook_id]
                new_cell_id = str(uuid.uuid4())
                
                new_cell = {
                    'id': new_cell_id,
                    'cell_type': 'code',
                    'source': code,
                    'outputs': serialized_outputs,
                    'execution_count': result.get('execution_count'),
                    'metadata': {
                        'created_by': 'ai_agent',
                        'description': description,
                        'created_at': datetime.utcnow().isoformat()
                    }
                }
                
                # æ·»åŠ åˆ° Notebook
                if 'cells' not in notebook:
                    notebook['cells'] = []
                notebook['cells'].append(new_cell)
                notebook['updated_at'] = datetime.utcnow()
                notebook['execution_count'] = result.get('execution_count', notebook.get('execution_count', 0))
                
                logger.info(f"[NotebookExecute] åˆ›å»ºæ–° Cell: {new_cell_id}")
            
            # æ ¼å¼åŒ–è¾“å‡º
            output_parts = []
            
            if description:
                output_parts.append(f"ğŸ“ {description}\n")
            
            for output in serialized_outputs:
                output_type = output.get('output_type', '')
                content = output.get('content', '')
                mime_type = output.get('mime_type', '')
                
                if output_type == 'stream':
                    output_parts.append(f"ğŸ“¤ è¾“å‡º:\n{content}")
                elif output_type == 'execute_result':
                    output_parts.append(f"âœ… ç»“æœ:\n{content}")
                elif output_type == 'error':
                    output_parts.append(f"âŒ é”™è¯¯:\n{content}")
                elif output_type == 'display_data':
                    if mime_type and 'image' in mime_type:
                        output_parts.append(f"ğŸ“Š [å›¾è¡¨å·²ç”Ÿæˆå¹¶æ˜¾ç¤ºåœ¨ Notebook ä¸­]")
                    else:
                        output_parts.append(f"ğŸ“‹ æ˜¾ç¤ºæ•°æ®:\n{str(content)[:500]}")
            
            if not output_parts:
                output_parts.append("âœ… ä»£ç æ‰§è¡ŒæˆåŠŸï¼ˆæ— è¾“å‡ºï¼‰")
            
            output_text = "\n".join(output_parts)
            
            return ToolResult(
                success=result.get('success', True),
                output=output_text,
                data={
                    "cell_id": new_cell_id,
                    "execution_count": result.get('execution_count'),
                    "execution_time_ms": result.get('execution_time_ms'),
                    "outputs": serialized_outputs,
                    "notebook_updated": new_cell_id is not None,
                    "new_cell": new_cell if new_cell_id else None
                }
            )
            
        except Exception as e:
            logger.error(f"[NotebookExecute] æ‰§è¡Œå¤±è´¥: {e}")
            return ToolResult(
                success=False,
                output=f"ä»£ç æ‰§è¡Œå¤±è´¥: {str(e)}",
                error=str(e)
            )


class NotebookVariablesTool(Tool):
    """
    è·å– Notebook å½“å‰çš„å˜é‡çŠ¶æ€
    
    å¸®åŠ© Agent äº†è§£å½“å‰ç¯å¢ƒä¸­æœ‰å“ªäº›æ•°æ®å¯ç”¨
    """
    name = "notebook_variables"
    description = """è·å– Notebook å†…æ ¸ä¸­å½“å‰å®šä¹‰çš„å˜é‡åˆ—è¡¨ã€‚
è¿”å›å˜é‡åã€ç±»å‹ã€ç®€è¦æè¿°ç­‰ä¿¡æ¯ã€‚
é€‚ç”¨äºï¼šäº†è§£å¯ç”¨æ•°æ®ã€æ£€æŸ¥æ•°æ®çŠ¶æ€ã€è°ƒè¯•ç­‰ã€‚"""
    parameters = {
        "type": "object",
        "properties": {
            "filter_type": {
                "type": "string",
                "description": "æŒ‰ç±»å‹è¿‡æ»¤ï¼Œå¦‚ 'DataFrame', 'ndarray', 'list' ç­‰ï¼ˆå¯é€‰ï¼‰"
            },
            "include_values": {
                "type": "boolean",
                "description": "æ˜¯å¦åŒ…å«å˜é‡å€¼é¢„è§ˆï¼Œé»˜è®¤ True"
            }
        },
        "required": []
    }
    
    def __init__(self, kernel_manager, notebook_id: str):
        self.kernel_manager = kernel_manager
        self.notebook_id = notebook_id
    
    async def execute(self, filter_type: str = None, include_values: bool = True, **kwargs) -> ToolResult:
        """è·å–å˜é‡åˆ—è¡¨"""
        logger.info(f"[NotebookVariables] notebook_id={self.notebook_id}, filter={filter_type}")
        
        try:
            kernel = self.kernel_manager.get_kernel(self.notebook_id)
            
            if not kernel:
                return ToolResult(
                    success=True,
                    output="å†…æ ¸å°šæœªå¯åŠ¨ï¼Œæ²¡æœ‰å¯ç”¨å˜é‡ã€‚",
                    data={"variables": {}}
                )
            
            # get_variables() è¿”å› Dict[str, str]ï¼Œå³ {å˜é‡å: ç±»å‹å}
            variables = kernel.get_variables()
            
            # åº”ç”¨è¿‡æ»¤
            if filter_type:
                variables = {
                    k: v for k, v in variables.items()
                    if filter_type.lower() in v.lower()
                }
            
            if not variables:
                return ToolResult(
                    success=True,
                    output=f"æ²¡æœ‰æ‰¾åˆ°{'ç±»å‹ä¸º ' + filter_type + ' çš„' if filter_type else ''}å˜é‡ã€‚",
                    data={"variables": {}}
                )
            
            # æ ¼å¼åŒ–è¾“å‡º
            output_parts = ["ğŸ“Š å½“å‰å˜é‡çŠ¶æ€:\n"]
            
            for name, var_type in variables.items():
                # ç±»å‹å›¾æ ‡
                icon = "ğŸ“¦"
                if 'DataFrame' in var_type:
                    icon = "ğŸ“Š"
                elif 'array' in var_type.lower() or 'ndarray' in var_type:
                    icon = "ğŸ”¢"
                elif 'list' in var_type or 'dict' in var_type:
                    icon = "ğŸ“‹"
                elif 'str' in var_type:
                    icon = "ğŸ“"
                elif 'int' in var_type or 'float' in var_type:
                    icon = "ğŸ”¢"
                
                line = f"{icon} {name}: {var_type}"
                
                # å¦‚æœéœ€è¦å€¼é¢„è§ˆï¼Œè·å–å˜é‡å€¼çš„ç®€è¦æè¿°
                if include_values:
                    try:
                        value = kernel.namespace.get(name)
                        if value is not None:
                            # è·å–ç®€è¦æè¿°
                            if hasattr(value, 'shape'):
                                line += f" (shape: {value.shape})"
                            elif hasattr(value, '__len__') and not isinstance(value, str):
                                line += f" (length: {len(value)})"
                            
                            # å€¼é¢„è§ˆ
                            repr_str = repr(value)
                            if len(repr_str) > 100:
                                repr_str = repr_str[:100] + "..."
                            line += f"\n   é¢„è§ˆ: {repr_str}"
                    except Exception as e:
                        logger.debug(f"è·å–å˜é‡ {name} é¢„è§ˆå¤±è´¥: {e}")
                
                output_parts.append(line)
            
            return ToolResult(
                success=True,
                output="\n".join(output_parts),
                data={"variables": variables}
            )
            
        except Exception as e:
            logger.error(f"[NotebookVariables] è·å–å˜é‡å¤±è´¥: {e}")
            return ToolResult(
                success=False,
                output=f"è·å–å˜é‡å¤±è´¥: {str(e)}",
                error=str(e)
            )


class NotebookCellTool(Tool):
    """
    æ“ä½œ Notebook å•å…ƒæ ¼
    
    æ”¯æŒæ·»åŠ ã€åˆ é™¤ã€æ›´æ–°å•å…ƒæ ¼
    """
    name = "notebook_cell"
    description = """æ“ä½œ Notebook çš„å•å…ƒæ ¼ã€‚
æ”¯æŒ: add (æ·»åŠ ), delete (åˆ é™¤), update (æ›´æ–°), get (è·å–)ã€‚
æ³¨æ„ï¼šä¿®æ”¹æ“ä½œéœ€è¦ç”¨æˆ·æˆæƒã€‚"""
    parameters = {
        "type": "object",
        "properties": {
            "action": {
                "type": "string",
                "enum": ["add", "delete", "update", "get"],
                "description": "æ“ä½œç±»å‹"
            },
            "cell_id": {
                "type": "string",
                "description": "å•å…ƒæ ¼ IDï¼ˆdelete/update/get éœ€è¦ï¼‰"
            },
            "cell_type": {
                "type": "string",
                "enum": ["code", "markdown"],
                "description": "å•å…ƒæ ¼ç±»å‹ï¼ˆadd æ—¶ä½¿ç”¨ï¼‰"
            },
            "content": {
                "type": "string",
                "description": "å•å…ƒæ ¼å†…å®¹ï¼ˆadd/update æ—¶ä½¿ç”¨ï¼‰"
            },
            "index": {
                "type": "integer",
                "description": "æ’å…¥ä½ç½®ï¼ˆadd æ—¶ä½¿ç”¨ï¼Œå¯é€‰ï¼‰"
            }
        },
        "required": ["action"]
    }
    
    def __init__(self, notebooks_store: dict, notebook_id: str, user_authorized: bool = False):
        self.notebooks_store = notebooks_store
        self.notebook_id = notebook_id
        self.user_authorized = user_authorized
    
    async def execute(
        self,
        action: str,
        cell_id: str = None,
        cell_type: str = "code",
        content: str = "",
        index: int = None,
        **kwargs
    ) -> ToolResult:
        """æ‰§è¡Œå•å…ƒæ ¼æ“ä½œ"""
        logger.info(f"[NotebookCell] action={action}, notebook_id={self.notebook_id}")
        
        # è·å– notebook
        notebook = self.notebooks_store.get(self.notebook_id)
        if not notebook:
            return ToolResult(
                success=False,
                output="Notebook ä¸å­˜åœ¨",
                error="notebook_not_found"
            )
        
        # æ£€æŸ¥æˆæƒï¼ˆget æ“ä½œä¸éœ€è¦ï¼‰
        if action in ['add', 'delete', 'update'] and not self.user_authorized:
            return ToolResult(
                success=False,
                output=f"æ“ä½œ '{action}' éœ€è¦ç”¨æˆ·æˆæƒã€‚è¯·å…ˆå¯ç”¨ã€Œå…è®¸ AI æ“ä½œ Notebookã€é€‰é¡¹ã€‚",
                error="authorization_required",
                data={"requires_authorization": True, "action": f"cell_{action}"}
            )
        
        try:
            if action == "get":
                return self._get_cells(notebook)
            elif action == "add":
                return self._add_cell(notebook, cell_type, content, index)
            elif action == "delete":
                return self._delete_cell(notebook, cell_id)
            elif action == "update":
                return self._update_cell(notebook, cell_id, content, cell_type)
            else:
                return ToolResult(
                    success=False,
                    output=f"æœªçŸ¥æ“ä½œ: {action}",
                    error="invalid_action"
                )
        except Exception as e:
            logger.error(f"[NotebookCell] æ“ä½œå¤±è´¥: {e}")
            return ToolResult(
                success=False,
                output=f"æ“ä½œå¤±è´¥: {str(e)}",
                error=str(e)
            )
    
    def _get_cells(self, notebook: dict) -> ToolResult:
        """è·å–æ‰€æœ‰å•å…ƒæ ¼æ‘˜è¦"""
        cells = notebook.get('cells', [])
        
        if not cells:
            return ToolResult(
                success=True,
                output="Notebook æ²¡æœ‰å•å…ƒæ ¼",
                data={"cells": []}
            )
        
        output_parts = [f"ğŸ““ Notebook å…±æœ‰ {len(cells)} ä¸ªå•å…ƒæ ¼:\n"]
        
        for i, cell in enumerate(cells):
            cell_type = cell.get('cell_type', 'code')
            source = cell.get('source', '')[:100]
            exec_count = cell.get('execution_count')
            has_output = bool(cell.get('outputs'))
            
            icon = "ğŸ’»" if cell_type == "code" else "ğŸ“"
            status = f"[{exec_count}]" if exec_count else "[_]"
            output_indicator = " ğŸ“¤" if has_output else ""
            
            output_parts.append(
                f"{icon} Cell {i+1} {status}{output_indicator}: {source}..."
            )
        
        return ToolResult(
            success=True,
            output="\n".join(output_parts),
            data={
                "cells": [
                    {
                        "id": c.get('id'),
                        "index": i,
                        "type": c.get('cell_type'),
                        "preview": c.get('source', '')[:100],
                        "execution_count": c.get('execution_count'),
                        "has_output": bool(c.get('outputs'))
                    }
                    for i, c in enumerate(cells)
                ]
            }
        )
    
    def _add_cell(self, notebook: dict, cell_type: str, content: str, index: int = None) -> ToolResult:
        """æ·»åŠ æ–°å•å…ƒæ ¼"""
        import uuid
        
        new_cell = {
            'id': str(uuid.uuid4()),
            'cell_type': cell_type,
            'source': content,
            'outputs': [],
            'execution_count': None,
            'metadata': {
                'created_by': 'ai_agent',
                'created_at': datetime.utcnow().isoformat()
            }
        }
        
        cells = notebook.get('cells', [])
        
        if index is not None and 0 <= index <= len(cells):
            cells.insert(index, new_cell)
            pos_msg = f"åœ¨ä½ç½® {index + 1}"
            actual_index = index
        else:
            cells.append(new_cell)
            pos_msg = "åœ¨æœ«å°¾"
            actual_index = len(cells) - 1
        
        notebook['cells'] = cells
        notebook['updated_at'] = datetime.utcnow()
        self.notebooks_store[self.notebook_id] = notebook
        
        return ToolResult(
            success=True,
            output=f"âœ… å·²{pos_msg}æ·»åŠ {'ä»£ç ' if cell_type == 'code' else 'Markdown'}å•å…ƒæ ¼",
            data={
                "cell_id": new_cell['id'],
                "index": actual_index,
                "notebook_updated": True,
                "new_cell": new_cell
            }
        )
    
    def _delete_cell(self, notebook: dict, cell_id: str) -> ToolResult:
        """åˆ é™¤å•å…ƒæ ¼"""
        if not cell_id:
            return ToolResult(
                success=False,
                output="éœ€è¦æŒ‡å®š cell_id",
                error="missing_cell_id"
            )
        
        cells = notebook.get('cells', [])
        original_count = len(cells)
        
        notebook['cells'] = [c for c in cells if c.get('id') != cell_id]
        
        if len(notebook['cells']) == original_count:
            return ToolResult(
                success=False,
                output=f"æœªæ‰¾åˆ° ID ä¸º {cell_id} çš„å•å…ƒæ ¼",
                error="cell_not_found"
            )
        
        notebook['updated_at'] = datetime.utcnow()
        self.notebooks_store[self.notebook_id] = notebook
        
        return ToolResult(
            success=True,
            output=f"âœ… å·²åˆ é™¤å•å…ƒæ ¼ {cell_id[:8]}...",
            data={"deleted_id": cell_id}
        )
    
    def _update_cell(self, notebook: dict, cell_id: str, content: str, cell_type: str = None) -> ToolResult:
        """æ›´æ–°å•å…ƒæ ¼"""
        if not cell_id:
            return ToolResult(
                success=False,
                output="éœ€è¦æŒ‡å®š cell_id",
                error="missing_cell_id"
            )
        
        for cell in notebook.get('cells', []):
            if cell.get('id') == cell_id:
                if content is not None:
                    cell['source'] = content
                if cell_type is not None:
                    cell['cell_type'] = cell_type
                cell['metadata'] = cell.get('metadata', {})
                cell['metadata']['updated_by'] = 'ai_agent'
                cell['metadata']['updated_at'] = datetime.utcnow().isoformat()
                
                notebook['updated_at'] = datetime.utcnow()
                self.notebooks_store[self.notebook_id] = notebook
                
                return ToolResult(
                    success=True,
                    output=f"âœ… å·²æ›´æ–°å•å…ƒæ ¼ {cell_id[:8]}...",
                    data={
                        "updated_id": cell_id,
                        "notebook_updated": True,
                        "updated_cell": cell
                    }
                )
        
        return ToolResult(
            success=False,
            output=f"æœªæ‰¾åˆ° ID ä¸º {cell_id} çš„å•å…ƒæ ¼",
            error="cell_not_found"
        )


class PipInstallTool(Tool):
    """
    å®‰è£… Python åŒ…
    
    å‡ºäºå®‰å…¨è€ƒè™‘ï¼Œåªå…è®¸å®‰è£…ç™½åå•ä¸­çš„åŒ…
    """
    name = "pip_install"
    description = """ä½¿ç”¨ pip å®‰è£… Python åŒ…ã€‚
å‡ºäºå®‰å…¨è€ƒè™‘ï¼Œåªèƒ½å®‰è£…é¢„å®šä¹‰ç™½åå•ä¸­çš„åŒ…ï¼ˆnumpy, pandas, sklearn ç­‰å¸¸ç”¨åº“ï¼‰ã€‚
æ³¨æ„ï¼šæ­¤æ“ä½œéœ€è¦ç”¨æˆ·æˆæƒã€‚"""
    parameters = {
        "type": "object",
        "properties": {
            "packages": {
                "type": "array",
                "items": {"type": "string"},
                "description": "è¦å®‰è£…çš„åŒ…åˆ—è¡¨ï¼Œå¦‚ ['pandas', 'scikit-learn==1.0']"
            },
            "upgrade": {
                "type": "boolean",
                "description": "æ˜¯å¦å‡çº§åˆ°æœ€æ–°ç‰ˆæœ¬",
                "default": False
            }
        },
        "required": ["packages"]
    }
    
    def __init__(self, user_authorized: bool = False):
        self.user_authorized = user_authorized
    
    async def execute(self, packages: List[str], upgrade: bool = False, **kwargs) -> ToolResult:
        """å®‰è£…åŒ…"""
        logger.info(f"[PipInstall] packages={packages}, upgrade={upgrade}")
        
        # æ£€æŸ¥æˆæƒ
        if not self.user_authorized:
            return ToolResult(
                success=False,
                output="å®‰è£…åŒ…éœ€è¦ç”¨æˆ·æˆæƒã€‚è¯·å…ˆå¯ç”¨ã€Œå…è®¸ AI æ“ä½œ Notebookã€é€‰é¡¹ã€‚",
                error="authorization_required",
                data={"requires_authorization": True, "action": "pip_install"}
            )
        
        # éªŒè¯åŒ…å
        blocked = []
        allowed = []
        
        for pkg in packages:
            # æå–åŒ…åï¼ˆå»æ‰ç‰ˆæœ¬å·ï¼‰
            pkg_name = re.split(r'[<>=!~]', pkg)[0].strip().lower()
            
            if pkg_name in ALLOWED_PACKAGES:
                allowed.append(pkg)
            else:
                blocked.append(pkg)
        
        if blocked:
            return ToolResult(
                success=False,
                output=f"ä»¥ä¸‹åŒ…ä¸åœ¨å…è®¸åˆ—è¡¨ä¸­: {', '.join(blocked)}\nå…è®¸çš„åŒ…åŒ…æ‹¬: numpy, pandas, matplotlib, scikit-learn, torch, requests, beautifulsoup4 ç­‰å¸¸ç”¨åº“ã€‚",
                error="packages_not_allowed",
                data={"blocked": blocked, "allowed": allowed}
            )
        
        if not allowed:
            return ToolResult(
                success=False,
                output="æ²¡æœ‰å¯å®‰è£…çš„åŒ…",
                error="no_packages"
            )
        
        try:
            # æ„å»º pip å‘½ä»¤
            cmd = [sys.executable, "-m", "pip", "install"]
            if upgrade:
                cmd.append("--upgrade")
            cmd.extend(allowed)
            
            logger.info(f"[PipInstall] æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
            
            # æ‰§è¡Œå®‰è£…ï¼ˆè®¾ç½®è¶…æ—¶ 5 åˆ†é’Ÿï¼‰
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            try:
                stdout, stderr = await asyncio.wait_for(
                    process.communicate(),
                    timeout=300
                )
            except asyncio.TimeoutError:
                process.kill()
                return ToolResult(
                    success=False,
                    output="å®‰è£…è¶…æ—¶ï¼ˆè¶…è¿‡ 5 åˆ†é’Ÿï¼‰",
                    error="timeout"
                )
            
            stdout_text = stdout.decode('utf-8', errors='ignore')
            stderr_text = stderr.decode('utf-8', errors='ignore')
            
            if process.returncode == 0:
                output_parts = [f"âœ… æˆåŠŸå®‰è£…: {', '.join(allowed)}"]
                
                # æå–å®‰è£…ä¿¡æ¯
                if "Successfully installed" in stdout_text:
                    match = re.search(r'Successfully installed (.+)', stdout_text)
                    if match:
                        output_parts.append(f"\nå®‰è£…è¯¦æƒ…: {match.group(1)}")
                
                return ToolResult(
                    success=True,
                    output="\n".join(output_parts),
                    data={"installed": allowed, "stdout": stdout_text}
                )
            else:
                return ToolResult(
                    success=False,
                    output=f"å®‰è£…å¤±è´¥:\n{stderr_text or stdout_text}",
                    error="pip_error",
                    data={"returncode": process.returncode}
                )
                
        except Exception as e:
            logger.error(f"[PipInstall] å®‰è£…å¤±è´¥: {e}")
            return ToolResult(
                success=False,
                output=f"å®‰è£…å¤±è´¥: {str(e)}",
                error=str(e)
            )


class WebScrapeTool(Tool):
    """
    ç½‘é¡µå†…å®¹çˆ¬å–å·¥å…·
    
    æ”¯æŒæå–æ–‡æœ¬ã€é“¾æ¥ã€è¡¨æ ¼ç­‰
    """
    name = "web_scrape"
    description = """çˆ¬å–ç½‘é¡µå†…å®¹ã€‚
å¯ä»¥æå–: text (çº¯æ–‡æœ¬), html (HTML), links (é“¾æ¥), tables (è¡¨æ ¼), all (å…¨éƒ¨)ã€‚
æ”¯æŒ CSS é€‰æ‹©å™¨ç²¾ç¡®å®šä½å…ƒç´ ã€‚"""
    parameters = {
        "type": "object",
        "properties": {
            "url": {
                "type": "string",
                "description": "è¦çˆ¬å–çš„ URL"
            },
            "extract": {
                "type": "string",
                "enum": ["text", "html", "links", "tables", "all"],
                "description": "æå–å†…å®¹ç±»å‹",
                "default": "text"
            },
            "selector": {
                "type": "string",
                "description": "CSS é€‰æ‹©å™¨ï¼ˆå¯é€‰ï¼‰ï¼Œç”¨äºå®šä½ç‰¹å®šå…ƒç´ "
            },
            "max_length": {
                "type": "integer",
                "description": "æœ€å¤§è¿”å›é•¿åº¦",
                "default": 5000
            }
        },
        "required": ["url"]
    }
    
    async def execute(
        self,
        url: str,
        extract: str = "text",
        selector: str = None,
        max_length: int = 5000,
        **kwargs
    ) -> ToolResult:
        """çˆ¬å–ç½‘é¡µ"""
        logger.info(f"[WebScrape] url={url}, extract={extract}")
        
        # æ£€æŸ¥ bs4 æ˜¯å¦å¯ç”¨
        if not BS4_AVAILABLE:
            return ToolResult(
                success=False,
                output="beautifulsoup4 æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…: pip install beautifulsoup4 lxml",
                error="bs4_not_installed"
            )
        
        # URL å®‰å…¨æ£€æŸ¥
        try:
            parsed = urlparse(url)
            
            # æ£€æŸ¥åè®®
            if parsed.scheme not in ('http', 'https'):
                return ToolResult(
                    success=False,
                    output=f"ä¸æ”¯æŒçš„ URL åè®®: {parsed.scheme}",
                    error="invalid_protocol"
                )
            
            # æ£€æŸ¥åŸŸåé»‘åå•
            hostname = parsed.hostname or ''
            for blocked in BLOCKED_DOMAINS:
                if hostname.startswith(blocked) or hostname.endswith(blocked) or blocked in hostname:
                    return ToolResult(
                        success=False,
                        output=f"å‡ºäºå®‰å…¨åŸå› ï¼Œæ— æ³•è®¿é—®æ­¤åŸŸå: {hostname}",
                        error="blocked_domain"
                    )
            
            # æ£€æŸ¥ç§æœ‰ IP åœ°å€
            if hostname.startswith('10.') or hostname.startswith('192.168.') or hostname.startswith('172.'):
                return ToolResult(
                    success=False,
                    output=f"æ— æ³•è®¿é—®ç§æœ‰ IP åœ°å€",
                    error="private_ip"
                )
                    
        except Exception as e:
            return ToolResult(
                success=False,
                output=f"æ— æ•ˆçš„ URL: {e}",
                error="invalid_url"
            )
        
        try:
            # å‘èµ·è¯·æ±‚
            async with httpx.AsyncClient(timeout=30.0, follow_redirects=True) as client:
                response = await client.get(
                    url,
                    headers={
                        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
                        "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
                    }
                )
                
                if response.status_code != 200:
                    return ToolResult(
                        success=False,
                        output=f"è¯·æ±‚å¤±è´¥: HTTP {response.status_code}",
                        error=f"http_{response.status_code}"
                    )
                
                # è§£æ HTML
                try:
                    soup = BeautifulSoup(response.text, 'lxml')
                except:
                    soup = BeautifulSoup(response.text, 'html.parser')
                
                # ç§»é™¤è„šæœ¬å’Œæ ·å¼
                for tag in soup(['script', 'style', 'noscript', 'iframe']):
                    tag.decompose()
                
                # å¦‚æœæœ‰é€‰æ‹©å™¨ï¼Œå®šä½åˆ°ç‰¹å®šå…ƒç´ 
                if selector:
                    elements = soup.select(selector)
                    if not elements:
                        return ToolResult(
                            success=True,
                            output=f"æœªæ‰¾åˆ°åŒ¹é…é€‰æ‹©å™¨ '{selector}' çš„å…ƒç´ ",
                            data={"url": url, "selector": selector}
                        )
                    # åˆ›å»ºä¸€ä¸ªæ–°çš„å®¹å™¨æ¥å­˜æ”¾é€‰ä¸­çš„å…ƒç´ 
                    try:
                        container = BeautifulSoup('<div></div>', 'lxml').div
                    except:
                        container = BeautifulSoup('<div></div>', 'html.parser').div
                    for el in elements:
                        container.append(el.extract())
                    soup = container
                
                result_data = {"url": url, "selector": selector}
                output_parts = [f"ğŸŒ ç½‘é¡µå†…å®¹ ({url[:50]}...):\n"]
                
                # æ ¹æ®æå–ç±»å‹å¤„ç†
                if extract == "text" or extract == "all":
                    text = soup.get_text(separator='\n', strip=True)
                    text = re.sub(r'\n{3,}', '\n\n', text)  # å‹ç¼©å¤šä½™ç©ºè¡Œ
                    text = text[:max_length]
                    result_data["text"] = text
                    output_parts.append(f"ğŸ“„ æ–‡æœ¬å†…å®¹:\n{text}")
                
                if extract == "links" or extract == "all":
                    links = []
                    for a in soup.find_all('a', href=True):
                        href = a['href']
                        text = a.get_text(strip=True)[:50]
                        if href.startswith(('http://', 'https://')):
                            links.append({"url": href, "text": text})
                    
                    links = links[:50]  # é™åˆ¶é“¾æ¥æ•°é‡
                    result_data["links"] = links
                    
                    if links:
                        output_parts.append(f"\n\nğŸ”— é“¾æ¥ ({len(links)} ä¸ª):")
                        for i, link in enumerate(links[:10], 1):
                            output_parts.append(f"\n{i}. [{link['text']}]({link['url']})")
                        if len(links) > 10:
                            output_parts.append(f"\n... è¿˜æœ‰ {len(links) - 10} ä¸ªé“¾æ¥")
                
                if extract == "tables" or extract == "all":
                    tables = []
                    for table in soup.find_all('table'):
                        rows = []
                        for tr in table.find_all('tr'):
                            cells = [td.get_text(strip=True) for td in tr.find_all(['td', 'th'])]
                            if cells:
                                rows.append(cells)
                        if rows:
                            tables.append(rows)
                    
                    tables = tables[:5]  # é™åˆ¶è¡¨æ ¼æ•°é‡
                    result_data["tables"] = tables
                    
                    if tables:
                        output_parts.append(f"\n\nğŸ“Š è¡¨æ ¼ ({len(tables)} ä¸ª):")
                        for i, table in enumerate(tables[:2], 1):
                            output_parts.append(f"\nè¡¨æ ¼ {i}:")
                            for row in table[:5]:
                                output_parts.append(f"  | {' | '.join(str(c)[:20] for c in row)} |")
                            if len(table) > 5:
                                output_parts.append(f"  ... è¿˜æœ‰ {len(table) - 5} è¡Œ")
                
                if extract == "html":
                    html = str(soup)[:max_length]
                    result_data["html"] = html
                    output_parts.append(f"ğŸ“„ HTML ç‰‡æ®µ:\n{html[:1000]}...")
                
                return ToolResult(
                    success=True,
                    output="\n".join(output_parts)[:max_length],
                    data=result_data
                )
                
        except httpx.TimeoutException:
            return ToolResult(
                success=False,
                output="è¯·æ±‚è¶…æ—¶ï¼ˆ30ç§’ï¼‰",
                error="timeout"
            )
        except Exception as e:
            logger.error(f"[WebScrape] çˆ¬å–å¤±è´¥: {e}")
            return ToolResult(
                success=False,
                output=f"çˆ¬å–å¤±è´¥: {str(e)}",
                error=str(e)
            )


class CodeAnalysisTool(Tool):
    """
    ä»£ç åˆ†æå’Œä¼˜åŒ–å»ºè®®å·¥å…·
    
    åˆ†æè¯­æ³•é”™è¯¯ã€ä»£ç é£æ ¼ã€æ€§èƒ½é—®é¢˜ç­‰
    """
    name = "code_analysis"
    description = """åˆ†æ Python ä»£ç ï¼Œæ£€æŸ¥è¯­æ³•é”™è¯¯ã€ä»£ç é£æ ¼å’Œæ€§èƒ½é—®é¢˜ã€‚
å¯ä»¥é’ˆå¯¹ç‰¹å®šé”™è¯¯ä¿¡æ¯æä¾›ä¿®å¤å»ºè®®ã€‚"""
    parameters = {
        "type": "object",
        "properties": {
            "code": {
                "type": "string",
                "description": "è¦åˆ†æçš„ä»£ç "
            },
            "error_message": {
                "type": "string",
                "description": "é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰"
            },
            "analysis_type": {
                "type": "string",
                "enum": ["syntax", "style", "performance", "all"],
                "description": "åˆ†æç±»å‹",
                "default": "all"
            }
        },
        "required": ["code"]
    }
    
    async def execute(
        self,
        code: str,
        error_message: str = None,
        analysis_type: str = "all",
        **kwargs
    ) -> ToolResult:
        """åˆ†æä»£ç """
        logger.info(f"[CodeAnalysis] analysis_type={analysis_type}, has_error={bool(error_message)}")
        
        issues = []
        suggestions = []
        
        # 1. è¯­æ³•æ£€æŸ¥
        if analysis_type in ["syntax", "all"]:
            try:
                compile(code, '<string>', 'exec')
            except SyntaxError as e:
                issues.append({
                    "type": "syntax_error",
                    "severity": "error",
                    "line": e.lineno,
                    "message": f"è¯­æ³•é”™è¯¯: {e.msg}",
                    "text": e.text
                })
        
        # 2. ä»£ç é£æ ¼æ£€æŸ¥
        if analysis_type in ["style", "all"]:
            lines = code.split('\n')
            
            # æ£€æŸ¥è¡Œé•¿åº¦
            for i, line in enumerate(lines, 1):
                if len(line) > 120:
                    issues.append({
                        "type": "style",
                        "severity": "warning",
                        "line": i,
                        "message": f"è¡Œé•¿åº¦è¶…è¿‡ 120 å­—ç¬¦ ({len(line)} å­—ç¬¦)"
                    })
            
            # æ£€æŸ¥æœªä½¿ç”¨çš„å¯¼å…¥
            import_pattern = r'^(?:from\s+(\S+)\s+)?import\s+(.+)$'
            imports = []
            for i, line in enumerate(lines, 1):
                match = re.match(import_pattern, line.strip())
                if match:
                    module = match.group(1) or match.group(2).split(',')[0].split(' as ')[0].strip()
                    imports.append((i, module))
            
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†å¯¼å…¥çš„æ¨¡å—
            code_without_imports = '\n'.join(
                l for l in lines if not re.match(r'^\s*(from|import)\s+', l)
            )
            for line_num, module in imports:
                # ç®€å•æ£€æŸ¥ï¼šæ¨¡å—åæ˜¯å¦å‡ºç°åœ¨ä»£ç ä¸­
                module_base = module.split('.')[0]
                if module_base not in code_without_imports:
                    issues.append({
                        "type": "style",
                        "severity": "info",
                        "line": line_num,
                        "message": f"å¯èƒ½æœªä½¿ç”¨çš„å¯¼å…¥: {module}"
                    })
            
            # æ£€æŸ¥ TODO/FIXME
            for i, line in enumerate(lines, 1):
                if 'TODO' in line or 'FIXME' in line:
                    issues.append({
                        "type": "style",
                        "severity": "info",
                        "line": i,
                        "message": f"å‘ç° TODO/FIXME æ³¨é‡Š"
                    })
        
        # 3. æ€§èƒ½æ£€æŸ¥
        if analysis_type in ["performance", "all"]:
            # æ£€æŸ¥ä½æ•ˆæ¨¡å¼
            perf_patterns = [
                (r'for\s+\w+\s+in\s+range\s*\(\s*len\s*\(', 
                 "å»ºè®®ä½¿ç”¨ enumerate() ä»£æ›¿ range(len())"),
                (r'\+=\s*\[', 
                 "åœ¨å¾ªç¯ä¸­ä½¿ç”¨ += [] æ•ˆç‡è¾ƒä½ï¼Œè€ƒè™‘ä½¿ç”¨ extend() æˆ–åˆ—è¡¨æ¨å¯¼"),
                (r'\[\w+\]\[\w+\]',
                 "é“¾å¼ç´¢å¼•å¯èƒ½å¯¼è‡´æ€§èƒ½é—®é¢˜ï¼Œè€ƒè™‘ä½¿ç”¨ .loc[] æˆ– .iloc[]"),
            ]
            
            for pattern, message in perf_patterns:
                if re.search(pattern, code, re.MULTILINE):
                    issues.append({
                        "type": "performance",
                        "severity": "warning",
                        "message": message
                    })
            
            # æ£€æŸ¥å¯èƒ½çš„ N+1 é—®é¢˜
            if re.search(r'for.+:\s*\n\s+.*\.(query|execute|find|get)\(', code):
                issues.append({
                    "type": "performance",
                    "severity": "warning",
                    "message": "å¯èƒ½å­˜åœ¨ N+1 æŸ¥è¯¢é—®é¢˜ï¼Œè€ƒè™‘æ‰¹é‡æ“ä½œ"
                })
        
        # 4. é’ˆå¯¹é”™è¯¯ä¿¡æ¯çš„å»ºè®®
        if error_message:
            suggestions.extend(self._analyze_error(error_message, code))
        
        # æ ¼å¼åŒ–è¾“å‡º
        output_parts = ["ğŸ” ä»£ç åˆ†æç»“æœ:\n"]
        
        if not issues and not suggestions:
            output_parts.append("âœ… æœªå‘ç°é—®é¢˜ï¼")
        else:
            # æŒ‰ä¸¥é‡ç¨‹åº¦æ’åº
            severity_order = {'error': 0, 'warning': 1, 'info': 2}
            issues.sort(key=lambda x: severity_order.get(x.get('severity', 'info'), 3))
            
            error_count = sum(1 for i in issues if i.get('severity') == 'error')
            warning_count = sum(1 for i in issues if i.get('severity') == 'warning')
            
            if error_count:
                output_parts.append(f"âŒ å‘ç° {error_count} ä¸ªé”™è¯¯")
            if warning_count:
                output_parts.append(f"âš ï¸ å‘ç° {warning_count} ä¸ªè­¦å‘Š")
            
            output_parts.append("")
            
            for issue in issues:
                severity = issue.get('severity', 'info')
                icon = 'âŒ' if severity == 'error' else ('âš ï¸' if severity == 'warning' else 'â„¹ï¸')
                line_info = f"[è¡Œ {issue['line']}] " if 'line' in issue else ""
                output_parts.append(f"{icon} {line_info}{issue['message']}")
            
            if suggestions:
                output_parts.append("\nğŸ’¡ ä¿®å¤å»ºè®®:")
                for i, suggestion in enumerate(suggestions, 1):
                    output_parts.append(f"{i}. {suggestion}")
        
        return ToolResult(
            success=True,
            output="\n".join(output_parts),
            data={
                "issues": issues,
                "suggestions": suggestions,
                "summary": {
                    "errors": sum(1 for i in issues if i.get('severity') == 'error'),
                    "warnings": sum(1 for i in issues if i.get('severity') == 'warning'),
                    "info": sum(1 for i in issues if i.get('severity') == 'info')
                }
            }
        )
    
    def _analyze_error(self, error_message: str, code: str) -> List[str]:
        """æ ¹æ®é”™è¯¯ä¿¡æ¯æä¾›ä¿®å¤å»ºè®®"""
        suggestions = []
        error_lower = error_message.lower()
        
        # NameError
        if 'nameerror' in error_lower:
            match = re.search(r"name '(\w+)' is not defined", error_message)
            if match:
                var_name = match.group(1)
                suggestions.append(f"å˜é‡ '{var_name}' æœªå®šä¹‰ï¼Œè¯·æ£€æŸ¥æ˜¯å¦æ‹¼å†™é”™è¯¯æˆ–éœ€è¦å…ˆå¯¼å…¥")
                # æ£€æŸ¥æ˜¯å¦æ˜¯å¸¸è§æ¨¡å—
                if var_name in ['np', 'pd', 'plt', 'sns', 'tf', 'torch']:
                    module_map = {
                        'np': 'numpy', 'pd': 'pandas', 'plt': 'matplotlib.pyplot',
                        'sns': 'seaborn', 'tf': 'tensorflow', 'torch': 'torch'
                    }
                    suggestions.append(f"å¦‚æœè¦ä½¿ç”¨ {var_name}ï¼Œè¯·æ·»åŠ : import {module_map.get(var_name, var_name)} as {var_name}")
        
        # TypeError
        elif 'typeerror' in error_lower:
            if 'not subscriptable' in error_lower:
                suggestions.append("å°è¯•å¯¹ä¸å¯ç´¢å¼•çš„å¯¹è±¡ä½¿ç”¨ä¸‹æ ‡ï¼Œæ£€æŸ¥å˜é‡ç±»å‹æ˜¯å¦æ­£ç¡®")
            elif 'not iterable' in error_lower:
                suggestions.append("å°è¯•éå†ä¸å¯è¿­ä»£å¯¹è±¡ï¼Œç¡®ä¿å˜é‡æ˜¯åˆ—è¡¨ã€å­—å…¸ç­‰å¯è¿­ä»£ç±»å‹")
            elif 'takes' in error_lower and 'argument' in error_lower:
                suggestions.append("å‡½æ•°å‚æ•°æ•°é‡ä¸åŒ¹é…ï¼Œæ£€æŸ¥å‡½æ•°å®šä¹‰å’Œè°ƒç”¨")
        
        # IndexError
        elif 'indexerror' in error_lower:
            suggestions.append("ç´¢å¼•è¶…å‡ºèŒƒå›´ï¼Œæ£€æŸ¥åˆ—è¡¨/æ•°ç»„é•¿åº¦")
            suggestions.append("å¯ä»¥ä½¿ç”¨ len() æ£€æŸ¥é•¿åº¦ï¼Œæˆ–ä½¿ç”¨ try-except æ•è·å¼‚å¸¸")
        
        # KeyError
        elif 'keyerror' in error_lower:
            suggestions.append("å­—å…¸é”®ä¸å­˜åœ¨ï¼Œä½¿ç”¨ .get() æ–¹æ³•å¯ä»¥é¿å…æ­¤é”™è¯¯")
            suggestions.append("æˆ–è€…å…ˆç”¨ 'key in dict' æ£€æŸ¥é”®æ˜¯å¦å­˜åœ¨")
        
        # ImportError / ModuleNotFoundError
        elif 'importerror' in error_lower or 'modulenotfound' in error_lower:
            match = re.search(r"No module named '(\w+)'", error_message)
            if match:
                module_name = match.group(1)
                suggestions.append(f"æ¨¡å— '{module_name}' æœªå®‰è£…ï¼Œå¯ä»¥ä½¿ç”¨ pip_install å·¥å…·å®‰è£…")
        
        # AttributeError
        elif 'attributeerror' in error_lower:
            suggestions.append("å¯¹è±¡æ²¡æœ‰æ­¤å±æ€§æˆ–æ–¹æ³•ï¼Œæ£€æŸ¥å¯¹è±¡ç±»å‹å’Œæ‹¼å†™")
            suggestions.append("ä½¿ç”¨ dir(obj) æˆ– type(obj) æŸ¥çœ‹å¯¹è±¡ä¿¡æ¯")
        
        # ValueError
        elif 'valueerror' in error_lower:
            if 'convert' in error_lower or 'literal' in error_lower:
                suggestions.append("ç±»å‹è½¬æ¢å¤±è´¥ï¼Œæ£€æŸ¥æ•°æ®æ ¼å¼æ˜¯å¦æ­£ç¡®")
            else:
                suggestions.append("å€¼é”™è¯¯ï¼Œæ£€æŸ¥è¾“å…¥æ•°æ®çš„èŒƒå›´å’Œæ ¼å¼")
        
        # FileNotFoundError
        elif 'filenotfound' in error_lower:
            suggestions.append("æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®")
            suggestions.append("å¯ä»¥ä½¿ç”¨ os.path.exists() å…ˆæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
        
        return suggestions


# ========== å¢å¼ºçš„ LiteratureSearchTool ==========

class EnhancedLiteratureSearchTool(Tool):
    """
    å¢å¼ºç‰ˆå­¦æœ¯æ–‡çŒ®æœç´¢å·¥å…·
    
    æ”¯æŒå¤šæºæœç´¢ã€è¿‡æ»¤é€‰é¡¹ã€è¯¦ç»†å…ƒæ•°æ®
    """
    name = "literature_search"
    description = """æœç´¢å­¦æœ¯è®ºæ–‡å’Œæ–‡çŒ®ã€‚
æ”¯æŒçš„æ¥æº: semantic_scholar, arxiv, pubmed, openalex, crossrefã€‚
å¯ä»¥æŒ‰å¹´ä»½ã€é¢†åŸŸè¿‡æ»¤ç»“æœã€‚"""
    parameters = {
        "type": "object",
        "properties": {
            "query": {
                "type": "string",
                "description": "æœç´¢å…³é”®è¯"
            },
            "source": {
                "type": "string",
                "enum": ["semantic_scholar", "arxiv", "pubmed", "openalex", "crossref"],
                "description": "æœç´¢æ¥æº",
                "default": "semantic_scholar"
            },
            "max_results": {
                "type": "integer",
                "description": "æœ€å¤§ç»“æœæ•°",
                "default": 5
            },
            "year_start": {
                "type": "integer",
                "description": "èµ·å§‹å¹´ä»½"
            },
            "year_end": {
                "type": "integer",
                "description": "ç»“æŸå¹´ä»½"
            },
            "fields": {
                "type": "string",
                "description": "ç ”ç©¶é¢†åŸŸè¿‡æ»¤ï¼ˆé€—å·åˆ†éš”ï¼‰"
            }
        },
        "required": ["query"]
    }
    
    def __init__(self):
        from app.services.literature_service import get_literature_service
        self.service = get_literature_service()
    
    async def execute(
        self,
        query: str,
        source: str = "semantic_scholar",
        max_results: int = 5,
        year_start: int = None,
        year_end: int = None,
        fields: str = None,
        **kwargs
    ) -> ToolResult:
        """æ‰§è¡Œå­¦æœ¯æ–‡çŒ®æœç´¢"""
        logger.info(f"[LiteratureSearch] query={query}, source={source}")
        
        try:
            # æ„å»ºæœç´¢å‚æ•°
            search_kwargs = {}
            if year_start and year_end:
                search_kwargs["year_range"] = (year_start, year_end)
            if fields:
                search_kwargs["fields_of_study"] = [f.strip() for f in fields.split(',')]
            
            # æ‰§è¡Œæœç´¢
            result = await self.service.search(
                query=query,
                source=source,
                limit=max_results,
                **search_kwargs
            )
            
            if "error" in result:
                return ToolResult(
                    success=False,
                    output=f"æœç´¢å¤±è´¥: {result['error']}",
                    error=result["error"]
                )
            
            papers = result.get("papers", [])
            
            if not papers:
                return ToolResult(
                    success=True,
                    output=f"æœªæ‰¾åˆ°å…³äº '{query}' çš„å­¦æœ¯è®ºæ–‡ã€‚",
                    data={"papers": [], "query": query, "source": source}
                )
            
            # æ ¼å¼åŒ–è¾“å‡º
            source_names = {
                "semantic_scholar": "Semantic Scholar",
                "arxiv": "arXiv",
                "pubmed": "PubMed",
                "openalex": "OpenAlex",
                "crossref": "Crossref"
            }
            
            output_parts = [f"ğŸ“š åœ¨ {source_names.get(source, source)} æœç´¢ '{query}' çš„ç»“æœ:\n"]
            
            for i, paper in enumerate(papers, 1):
                # ä½œè€…
                authors = paper.authors[:3] if paper.authors else []
                author_names = [a.get("name", "Unknown") for a in authors]
                author_str = ", ".join(author_names)
                if len(paper.authors) > 3:
                    author_str += " et al."
                
                output_parts.append(f"\nã€{i}ã€‘{paper.title}")
                if paper.year:
                    output_parts.append(f" ({paper.year})")
                output_parts.append(f"\nğŸ‘¥ {author_str}")
                
                if paper.venue:
                    output_parts.append(f"\nğŸ“ {paper.venue}")
                
                if paper.citation_count > 0:
                    output_parts.append(f"\nğŸ“Š å¼•ç”¨: {paper.citation_count}")
                
                if paper.abstract:
                    abstract = paper.abstract[:200]
                    if len(paper.abstract) > 200:
                        abstract += "..."
                    output_parts.append(f"\nğŸ“ {abstract}")
                
                if paper.url:
                    output_parts.append(f"\nğŸ”— {paper.url}")
                
                if paper.pdf_url:
                    output_parts.append(f"\nğŸ“„ PDF: {paper.pdf_url}")
            
            return ToolResult(
                success=True,
                output="\n".join(output_parts),
                data={
                    "papers": [self._paper_to_dict(p) for p in papers],
                    "query": query,
                    "source": source,
                    "total": result.get("total", len(papers))
                }
            )
            
        except Exception as e:
            logger.error(f"[LiteratureSearch] é”™è¯¯: {e}")
            return ToolResult(
                success=False,
                output=f"æœç´¢é”™è¯¯: {str(e)}",
                error=str(e)
            )
    
    def _paper_to_dict(self, paper) -> dict:
        """å°†è®ºæ–‡å¯¹è±¡è½¬ä¸ºå­—å…¸"""
        return {
            "source": paper.source,
            "external_id": paper.external_id,
            "title": paper.title,
            "abstract": paper.abstract,
            "authors": paper.authors,
            "year": paper.year,
            "venue": paper.venue,
            "citation_count": paper.citation_count,
            "reference_count": paper.reference_count,
            "url": paper.url,
            "pdf_url": paper.pdf_url,
            "arxiv_id": paper.arxiv_id,
            "doi": paper.doi,
            "fields_of_study": paper.fields_of_study
        }


# ========== å·¥å…·å·¥å‚å‡½æ•° ==========

def create_notebook_tools(
    kernel_manager,
    notebooks_store: dict,
    notebook_id: str,
    user_authorized: bool = False
) -> List[Tool]:
    """
    åˆ›å»º Notebook ä¸“ç”¨å·¥å…·é›†
    
    Args:
        kernel_manager: å†…æ ¸ç®¡ç†å™¨
        notebooks_store: notebooks å­˜å‚¨å­—å…¸
        notebook_id: Notebook ID
        user_authorized: ç”¨æˆ·æ˜¯å¦æˆæƒæ“ä½œ
        
    Returns:
        å·¥å…·åˆ—è¡¨
    """
    return [
        NotebookExecuteTool(kernel_manager, notebook_id, user_authorized),
        NotebookVariablesTool(kernel_manager, notebook_id),
        NotebookCellTool(notebooks_store, notebook_id, user_authorized),
        PipInstallTool(user_authorized),
        WebScrapeTool(),
        CodeAnalysisTool(),
        EnhancedLiteratureSearchTool(),
    ]
