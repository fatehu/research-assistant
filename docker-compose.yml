services:
  # PostgreSQL 数据库 (带 pgvector 向量扩展)
  postgres:
    image: pgvector/pgvector:pg16
    container_name: research_postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-research_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-research_password_123}
      POSTGRES_DB: ${POSTGRES_DB:-research_assistant}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backend/init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-research_user} -d ${POSTGRES_DB:-research_assistant}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - research_network

  # Redis 缓存
  redis:
    image: redis:7-alpine
    container_name: research_redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - research_network

  # FastAPI 后端
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: research_backend
    environment:
      - DATABASE_URL=${DATABASE_URL:-postgresql://research_user:research_password_123@postgres:5432/research_assistant}
      - REDIS_URL=${REDIS_URL:-redis://redis:6379/0}
      - SECRET_KEY=${SECRET_KEY:-your-super-secret-key-change-this-in-production-min-32-chars}
      - ALGORITHM=${ALGORITHM:-HS256}
      - ACCESS_TOKEN_EXPIRE_MINUTES=${ACCESS_TOKEN_EXPIRE_MINUTES:-1440}
      - DEFAULT_LLM_PROVIDER=${DEFAULT_LLM_PROVIDER:-deepseek}
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY}
      - DEEPSEEK_BASE_URL=${DEEPSEEK_BASE_URL:-https://api.deepseek.com}
      - DEEPSEEK_MODEL=${DEEPSEEK_MODEL:-deepseek-chat}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL:-https://api.openai.com/v1}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o}
      - ALIYUN_API_KEY=${ALIYUN_API_KEY}
      - ALIYUN_BASE_URL=${ALIYUN_BASE_URL:-https://dashscope.aliyuncs.com/compatible-mode/v1}
      - ALIYUN_MODEL=${ALIYUN_MODEL:-qwen-plus}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://host.docker.internal:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3}
      - EMBEDDING_PROVIDER=${EMBEDDING_PROVIDER:-aliyun}
      - ALIYUN_EMBEDDING_API_KEY=${ALIYUN_EMBEDDING_API_KEY}
      - ALIYUN_EMBEDDING_MODEL=${ALIYUN_EMBEDDING_MODEL:-text-embedding-v2}
      - SERPER_API_KEY=${SERPER_API_KEY}
      - REACT_MAX_ITERATIONS=${REACT_MAX_ITERATIONS:-5}
    ports:
      - "8000:8000"
    volumes:
      - ./backend:/app
      - backend_uploads:/app/uploads
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    command: >
      sh -c "alembic upgrade head && uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload"
    networks:
      - research_network

  # React 前端
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: research_frontend
    environment:
      - VITE_API_BASE_URL=${VITE_API_BASE_URL:-http://localhost:8000}
      - VITE_WS_BASE_URL=${VITE_WS_BASE_URL:-ws://localhost:8000}
    ports:
      - "3000:3000"
    volumes:
      - ./frontend:/app
      - /app/node_modules
    depends_on:
      - backend
    command: npm run dev -- --host 0.0.0.0
    networks:
      - research_network

networks:
  research_network:
    driver: bridge

volumes:
  postgres_data:
  redis_data:
  backend_uploads:
